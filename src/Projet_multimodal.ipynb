{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4M1HSV2rBNua"
   },
   "source": [
    "# Initialisation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 643,
     "status": "ok",
     "timestamp": 1608819845178,
     "user": {
      "displayName": "Aya Lamhandaz",
      "photoUrl": "",
      "userId": "12225870635110355962"
     },
     "user_tz": -60
    },
    "id": "vLjNt6NeGQpq"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JPKpWIc9GVWh"
   },
   "source": [
    "# Import des données "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xCahYHEcIA29"
   },
   "source": [
    "Dans txt_file, pour chaque ligne on retrouve : \n",
    "* l'identifiant du morceau \n",
    "* le genre associé à ce morceau \n",
    "* Le numéro et la fréquence des mots contenus dans ce morceau "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 1994,
     "status": "ok",
     "timestamp": 1608819853675,
     "user": {
      "displayName": "Aya Lamhandaz",
      "photoUrl": "",
      "userId": "12225870635110355962"
     },
     "user_tz": -60
    },
    "id": "a_fztZhsHGFx"
   },
   "outputs": [],
   "source": [
    "path = \"./msx_lyrics_genre.txt\"\n",
    "\n",
    "identifiants = []\n",
    "labels = []\n",
    "lyrics = {}\n",
    "\n",
    "with open(path, \"r\") as file:\n",
    "    reader = file.readlines()\n",
    "    for i in range(len(reader)) : \n",
    "      morceau = reader[i].split(' ')\n",
    "      identifiants.append(morceau[0])\n",
    "      labels.append(morceau[1])\n",
    "      lyrics[i] = morceau[2:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 751,
     "status": "ok",
     "timestamp": 1608819862409,
     "user": {
      "displayName": "Aya Lamhandaz",
      "photoUrl": "",
      "userId": "12225870635110355962"
     },
     "user_tz": -60
    },
    "id": "Jub2glrlHpYR",
    "outputId": "0e453b27-d208-43b9-ab11-41f576856b20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14750\n",
      "TRAAIAE128F42AC53D Country 1:9 3:4 4:4 6:3 7:1 8:2 9:4 10:5 11:5 12:1 13:5 15:2 19:2 21:3 26:3 27:2 28:3 31:1 34:3 39:4 45:2 46:1 49:2 62:2 64:1 66:3 70:4 75:3 81:1 99:1 107:5 119:3 121:2 124:2 127:1 171:1 203:4 216:2 245:1 270:1 308:1 355:1 375:1 398:1 439:1 468:2 510:1 546:1 581:1 844:3 955:1 961:1 1281:1 1662:2 2453:2\n",
      "\n",
      "TRAAIAE128F42AC53D\n",
      "Country\n",
      "['1:9', '3:4', '4:4', '6:3', '7:1', '8:2', '9:4', '10:5', '11:5', '12:1', '13:5', '15:2', '19:2', '21:3', '26:3', '27:2', '28:3', '31:1', '34:3', '39:4', '45:2', '46:1', '49:2', '62:2', '64:1', '66:3', '70:4', '75:3', '81:1', '99:1', '107:5', '119:3', '121:2', '124:2', '127:1', '171:1', '203:4', '216:2', '245:1', '270:1', '308:1', '355:1', '375:1', '398:1', '439:1', '468:2', '510:1', '546:1', '581:1', '844:3', '955:1', '961:1', '1281:1', '1662:2', '2453:2\\n']\n"
     ]
    }
   ],
   "source": [
    "print(len(reader)) \n",
    "# print(len(identifiants))\n",
    "# print(len(labels))\n",
    "# print(len(lyrics))\n",
    "print(reader[6])\n",
    "print(identifiants[6])\n",
    "print(labels[6])\n",
    "print(lyrics[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XeZb6oRBJGEt"
   },
   "source": [
    "#Preprocessing des données "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pgSzt20TJKS8"
   },
   "source": [
    "On va pas utiliser l'identifiant pour notre dataset, on a donc les labels et lyrics à normaliser. On commence par les labels. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ewl9PTCCJXSE"
   },
   "source": [
    "##Labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 703,
     "status": "ok",
     "timestamp": 1608820373461,
     "user": {
      "displayName": "Aya Lamhandaz",
      "photoUrl": "",
      "userId": "12225870635110355962"
     },
     "user_tz": -60
    },
    "id": "PGpDvE72JIPC",
    "outputId": "16cf173e-358f-404a-c4c9-6990c1925e77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Rap': 14749, 'Metal': 14748, 'Jazz': 14712, 'Pop': 14744, 'Reggae': 14736, 'Rock': 14745, 'Country': 14740, 'Punk': 14671, 'Folk': 14683, 'RnB': 14747, 'Electronic': 14706, 'Latin': 14724, 'Blues': 14584, 'New_Age': 14010, 'World': 14270}\n",
      "15\n",
      "[14749, 14748, 14712, 14744, 14736]\n"
     ]
    }
   ],
   "source": [
    "label_vocab = {label: i for i,label in enumerate(labels)}\n",
    "print(label_vocab)\n",
    "print(len(label_vocab)) #il y'a 15 genres de musique \n",
    "\n",
    "labels_int = [label_vocab[label] for label in labels]\n",
    "print(labels_int[0:5]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SqVbuvpSKykv"
   },
   "source": [
    "## Lyrics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yCYt-TOHL1-r"
   },
   "source": [
    "Lyrics sous forme de bag-of-word pour éviter d'avoir des problèmes de droit d'auteur. On a un dictionnaire de 5000 mots et à chaque x:y : x correspond à l'indice du mot dans le dictionnaire (il commence à un), y correspond au nombre de fois que ce mot est apparu dans cette chanson. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LjeuqBgTTQZP"
   },
   "source": [
    "Pour choisir max_len on va regarder combien chaque morceau comporte de mots, puis on va tronquer à la valeur qui nous parait la moins discriminante pour les données. On peut tronquer à 250. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 348
    },
    "executionInfo": {
     "elapsed": 596,
     "status": "ok",
     "timestamp": 1608822816752,
     "user": {
      "displayName": "Aya Lamhandaz",
      "photoUrl": "",
      "userId": "12225870635110355962"
     },
     "user_tz": -60
    },
    "id": "wMw4jHRTTeEe",
    "outputId": "314596f6-6c91-4bff-eb16-50aa5db92646"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.723e+03, 6.941e+03, 4.341e+03, 8.730e+02, 4.420e+02, 2.820e+02,\n",
       "        1.050e+02, 3.500e+01, 6.000e+00, 2.000e+00]),\n",
       " array([  1. ,  43.7,  86.4, 129.1, 171.8, 214.5, 257.2, 299.9, 342.6,\n",
       "        385.3, 428. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "len_lyrics = []\n",
    "for i in range(len(lyrics)):\n",
    "  len_lyrics.append(len(lyrics[i]))\n",
    "\n",
    "plt.hist(len_lyrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YdoUI5ytMfWU"
   },
   "source": [
    "Pour chaque morceau on va avoir deux listes : l'une avec les mots présents dans la chanson et l'autre avec la fréquence d'apparition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "executionInfo": {
     "elapsed": 1578,
     "status": "ok",
     "timestamp": 1608823076175,
     "user": {
      "displayName": "Aya Lamhandaz",
      "photoUrl": "",
      "userId": "12225870635110355962"
     },
     "user_tz": -60
    },
    "id": "ddvG-jbJKz1T"
   },
   "outputs": [],
   "source": [
    "max_len = 250\n",
    "seen_words = np.zeros((len(lyrics),max_len))\n",
    "words_frequency = np.zeros((len(lyrics),max_len))\n",
    "\n",
    "for i in range(len(lyrics)): \n",
    "  s = [lyric.split(':')[0] for lyric in lyrics[i] ]\n",
    "  l = [lyric.split(':')[1] for lyric in lyrics[i] ]\n",
    "  l[-1] = l[-1].split('\\n')[0]\n",
    "  seen_words[i,:min(max_len,len(s))] = s[:min(max_len,len(s))]\n",
    "  words_frequency[i,:min(max_len,len(l))] = l[:min(max_len,len(l))] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 642,
     "status": "ok",
     "timestamp": 1608823080697,
     "user": {
      "displayName": "Aya Lamhandaz",
      "photoUrl": "",
      "userId": "12225870635110355962"
     },
     "user_tz": -60
    },
    "id": "Rg0O-ONUPgeY",
    "outputId": "0c69351d-6cb2-4ac6-fc75-4073dacb0ec3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 2. 3. ... 0. 0. 0.]\n",
      " [1. 2. 3. ... 0. 0. 0.]\n",
      " [1. 2. 3. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 2. 3. ... 0. 0. 0.]\n",
      " [1. 2. 4. ... 0. 0. 0.]\n",
      " [1. 2. 3. ... 0. 0. 0.]]\n",
      "[[39. 30. 10. ...  0.  0.  0.]\n",
      " [ 4. 11. 19. ...  0.  0.  0.]\n",
      " [23. 18. 31. ...  0.  0.  0.]\n",
      " ...\n",
      " [11. 31. 42. ...  0.  0.  0.]\n",
      " [ 3. 14.  7. ...  0.  0.  0.]\n",
      " [25.  8.  6. ...  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "print(seen_words)\n",
    "print(words_frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "38o_FtQETEI9"
   },
   "source": [
    "## Construction de X et Y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "executionInfo": {
     "elapsed": 4030,
     "status": "ok",
     "timestamp": 1608823102567,
     "user": {
      "displayName": "Aya Lamhandaz",
      "photoUrl": "",
      "userId": "12225870635110355962"
     },
     "user_tz": -60
    },
    "id": "pRq8Z1jWTJq_"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "max_len = 250\n",
    "batch_size = 64\n",
    "embed_size = 128\n",
    "hidden_size = 128\n",
    "device = torch.device('cuda') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 701,
     "status": "ok",
     "timestamp": 1608825098286,
     "user": {
      "displayName": "Aya Lamhandaz",
      "photoUrl": "",
      "userId": "12225870635110355962"
     },
     "user_tz": -60
    },
    "id": "yHpsPF_DbIm7",
    "outputId": "12ffe4e2-4342-4092-a230-47b209e20c5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 1]\n",
      " [0 1 1 1 0 1]]\n",
      "[0 0 0]\n",
      "[0 0 1]\n"
     ]
    }
   ],
   "source": [
    "X = np.random.randint(2,size=(2,6))\n",
    "print(X)\n",
    "print(X[0,:3])\n",
    "print(X[0,3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 653,
     "status": "ok",
     "timestamp": 1608825191323,
     "user": {
      "displayName": "Aya Lamhandaz",
      "photoUrl": "",
      "userId": "12225870635110355962"
     },
     "user_tz": -60
    },
    "id": "GZyrNczsVEwW",
    "outputId": "9a97404c-4fb6-4c73-f18c-3f355a778aee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([14750, 500])\n",
      "torch.Size([14750])\n"
     ]
    }
   ],
   "source": [
    "X = np.zeros((len(lyrics), max_len*2)) #on va concaténer seen_words et words_frequency a la suite \n",
    "\n",
    "for i in range(len(lyrics)):\n",
    "  X[i,:max_len] = seen_words[i] \n",
    "  X[i,max_len:] = words_frequency[i]\n",
    "\n",
    "X = torch.from_numpy(X)\n",
    "Y = torch.LongTensor(labels_int)\n",
    "\n",
    "print(X.size())\n",
    "print(Y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 708,
     "status": "ok",
     "timestamp": 1608825262962,
     "user": {
      "displayName": "Aya Lamhandaz",
      "photoUrl": "",
      "userId": "12225870635110355962"
     },
     "user_tz": -60
    },
    "id": "5lNrLpwwWBET",
    "outputId": "dee3b588-56fc-452e-fa38-929ae305c655"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10325, 500]) torch.Size([4425, 500])\n",
      "torch.Size([10325]) torch.Size([4425])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.3)\n",
    "\n",
    "print(X_train.size(),X_test.size())\n",
    "print(Y_train.size(),Y_test.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "executionInfo": {
     "elapsed": 691,
     "status": "ok",
     "timestamp": 1608825310218,
     "user": {
      "displayName": "Aya Lamhandaz",
      "photoUrl": "",
      "userId": "12225870635110355962"
     },
     "user_tz": -60
    },
    "id": "QZu4uApIXRk5"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "train_set = TensorDataset(X_train, Y_train)\n",
    "test_set = TensorDataset(X_test, Y_test)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=False) #je les ai déjà shuffle avec train_test_split\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4kTfXhDDYTxW"
   },
   "source": [
    "## Fonctions pour les modèles : fit, perf et pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "executionInfo": {
     "elapsed": 672,
     "status": "ok",
     "timestamp": 1608825655450,
     "user": {
      "displayName": "Aya Lamhandaz",
      "photoUrl": "",
      "userId": "12225870635110355962"
     },
     "user_tz": -60
    },
    "id": "PF_JNHsBYOWD"
   },
   "outputs": [],
   "source": [
    "def perf(model, loader):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model.eval()\n",
    "    total_loss = correct = num = 0\n",
    "    for x, y in loader:\n",
    "      with torch.no_grad():\n",
    "        x_seen_words = x[:,:max_len] \n",
    "        x_words_frequency = x[:,max_len:]\n",
    "        y_scores = model(x_seen_words,x_words_frequency)\n",
    "        loss = criterion(y_scores, y)\n",
    "        y_pred = torch.max(y_scores, 1)[1]\n",
    "        correct += torch.sum(y_pred.data == y)\n",
    "        total_loss += loss.item()\n",
    "        num += len(y)\n",
    "    return total_loss / num, correct.item() / num\n",
    "\n",
    "def fit(model, epochs):\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = num = 0\n",
    "        for x, y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            x_seen_words = x[:,:max_len] \n",
    "            x_words_frequency = x[:,max_len:]\n",
    "            y_scores = model(x_seen_words,x_words_frequency)\n",
    "            loss = criterion(y_scores, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            num += len(y)\n",
    "        print(epoch, total_loss / num, *perf(model, test_loader))\n",
    "\n",
    "def predict(model,loader):\n",
    "   output = []\n",
    "   for x, y in loader:\n",
    "     with torch.no_grad():\n",
    "       x_seen_words = x[:, :max_len]\n",
    "       x_words_frequency = x[:, :max_len]\n",
    "       y_scores = self(x_seen_words, x_words_frequency)\n",
    "       y_pred = y_scores > 0.5\n",
    "       output.append(y_pred.int())\n",
    "   return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t0Mb_WNde9aN"
   },
   "source": [
    "#On commence par tester un RNN multimodal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 658,
     "status": "ok",
     "timestamp": 1608826854930,
     "user": {
      "displayName": "Aya Lamhandaz",
      "photoUrl": "",
      "userId": "12225870635110355962"
     },
     "user_tz": -60
    },
    "id": "rwxMP_RhfClX",
    "outputId": "03ed173d-1821-44b6-d9db-eeaf470f0715"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embed): Embedding(14750, 128)\n",
       "  (seen_words_rnn): GRU(128, 128, batch_first=True)\n",
       "  (words_frequency_rnn): GRU(128, 128, batch_first=True)\n",
       "  (seen_words_dropout): Dropout(p=0.3, inplace=False)\n",
       "  (words_frequency_dropout): Dropout(p=0.3, inplace=False)\n",
       "  (linear): Linear(in_features=256, out_features=15, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 91,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class RNN(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.embed = nn.Embedding(len(lyrics), embed_size)\n",
    "    self.seen_words_rnn = nn.GRU(embed_size,hidden_size,num_layers=1,bidirectional=False, batch_first=True)\n",
    "    self.words_frequency_rnn = nn.GRU(embed_size,hidden_size,num_layers=1,bidirectional=False, batch_first=True)\n",
    "    self.seen_words_dropout = nn.Dropout(0.3)\n",
    "    self.words_frequency_dropout = nn.Dropout(0.3)\n",
    "    self.linear = nn.Linear(hidden_size*2,out_features=len(label_vocab)) #*2 parce que j'ai deux couches \n",
    "  \n",
    "  def forward(self,x_seen_words,x_words_frequency):\n",
    "    sw_embed = self.embed(x_seen_words)\n",
    "    wf_embed = self.embed(x_words_frequency)\n",
    "    output_sw,hidden_sw = self.seen_words_rnn(sw_embed)\n",
    "    output_wf,hidden_wf = self.words_frequency_rnn(wf_embed)\n",
    "    sw_drop = self.seen_words_dropout(hidden_sw)\n",
    "    wf_drop = self.words_frequency_dropout(hidden_wf)\n",
    "    cat = torch.cat((sw_drop,wf_drop),-1) #concatene et renvoie un tenseur \n",
    "    return self.decision(cat.contiguous())\n",
    "  \n",
    "rnn_model = RNN()\n",
    "rnn_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "executionInfo": {
     "elapsed": 570,
     "status": "error",
     "timestamp": 1608827151186,
     "user": {
      "displayName": "Aya Lamhandaz",
      "photoUrl": "",
      "userId": "12225870635110355962"
     },
     "user_tz": -60
    },
    "id": "73Jal1ZTizVC",
    "outputId": "33176241-a80b-41f8-cbdf-be2ff34ea2db"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-1f884a04dd2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx_sw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mx_wf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mrnn_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_sw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_wf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-91-239fce4c5ec3>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x_seen_words, x_words_frequency)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_seen_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_words_frequency\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0msw_embed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_seen_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mwf_embed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_words_frequency\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0moutput_sw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden_sw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen_words_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msw_embed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m         return F.embedding(\n\u001b[1;32m    125\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1850\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1852\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected tensor for argument #1 'indices' to have scalar type Long; but got torch.DoubleTensor instead (while checking arguments for embedding)"
     ]
    }
   ],
   "source": [
    "x_sw = X[:3,:max_len]\n",
    "x_wf = X[:3,max_len:]\n",
    "\n",
    "rnn_model(x_sw,x_wf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "apVgYvQqjeQ-"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPpNUpbMfQb4cTzq/hO19Tm",
   "name": "Projet_multimodal.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
